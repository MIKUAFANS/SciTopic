export OMP_NUM_THREADS=1

CUDA_VISIBLE_DEVICES="5,6" torchrun --nproc_per_node 2 \
-m FlagEmbedding.finetune.embedder.encoder_only.m3 \
--output_dir result/bge-m3-finetune \
--model_name_or_path pretrained/bge-m3 \
--train_data output/fine_tune/AI-DM_file.jsonl \
--cache_dir ./cache/model \
--cache_path ./cache/data \
--train_group_size 8 \
--query_max_len 64 \
--passage_max_len 64 \
--pad_to_multiple_of 8 \
--knowledge_distillation True \
--same_dataset_within_batch True \
--small_threshold 0 \
--drop_threshold 0 \
--output_dir ./finetune_result \
--overwrite_output_dir \
--learning_rate 1e-5 \
--fp16 \
--num_train_epochs 3 \
--per_device_train_batch_size 2 \
--dataloader_drop_last True \
--warmup_ratio 0.1 \
--logging_steps 1 \
--save_steps 1000 \
--negatives_cross_device \
--temperature 0.02 \
--sentence_pooling_method cls \
--normalize_embeddings True \
--kd_loss_type m3_kd_loss \
--unified_finetuning True \
--use_self_distill True \
--fix_encoder False \
--self_distill_start_step 0